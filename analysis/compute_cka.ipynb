{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd4fab41",
   "metadata": {},
   "source": [
    "# CKA\n",
    "Compute CKA, plot and save CKA matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c32b57e-fe18-4061-9bd1-e8bfc4f91225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from util_cka import cka, gram_linear\n",
    "\n",
    "sys.path.append('../')\n",
    "from sample_batch_data import get_data_info, get_batch\n",
    "from signal_propagation import get_activation\n",
    "from set_config import generate_variant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c31798",
   "metadata": {},
   "source": [
    "## Functions for CKA computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef1d6faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cka(activation_1, activation_2, reward_state_action, timestep=-1):\n",
    "    \"\"\"Compute CKA for either return-to-go, state, or action.\n",
    "\n",
    "    Args:\n",
    "        activation_1 (np.ndarray[batchsize, represemtation_dim, time_step_in_context]): Neural activation vector.\n",
    "        activation_2 (np.ndarray[batchsize, represemtation_dim, time_step_in_context]): Neural activation vector.\n",
    "        reward_state_action (str): \"reward\" (return-to-go), \"state\", or \"action\".\n",
    "        timestep (int, optional): Activation at this timestep is used for CKA computation. Defaults to -1.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: scalar CKA\n",
    "    \"\"\"\n",
    "    # Input is sequence of [..., return-to-go, state, action]\n",
    "    if reward_state_action == \"reward\":\n",
    "        idx = timestep * 3\n",
    "    elif reward_state_action == \"state\":\n",
    "        idx = timestep * 2\n",
    "    elif reward_state_action == \"action\":\n",
    "        idx = timestep * 1\n",
    "    else:\n",
    "        print(\"Specify either 'reward', 'state', or 'action'.\")\n",
    "\n",
    "    if len(activation_1.shape) == 3:\n",
    "        activation_1 = activation_1[:, :, idx]\n",
    "    elif len(activation_1.shape) == 4:\n",
    "        activation_1 = activation_1[:, :, idx, idx]\n",
    "    if len(activation_2.shape) == 3:\n",
    "        activation_2 = activation_2[:, :, idx]\n",
    "    elif len(activation_2.shape) == 4:\n",
    "        activation_2 = activation_2[:, :, idx, idx]\n",
    "\n",
    "    cka_from_examples = cka(\n",
    "        gram_linear(activation_1.numpy()),\n",
    "        gram_linear(activation_2.numpy()),\n",
    "        debiased=True,\n",
    "    )\n",
    "\n",
    "    return cka_from_examples\n",
    "\n",
    "\n",
    "def plot_cka(\n",
    "    path_to_save_figure,\n",
    "    cka_matrix,\n",
    "    reward_state_action,\n",
    "    model1,\n",
    "    model2,\n",
    "    env_name,\n",
    "    dataset_name,\n",
    "    seed,\n",
    "    epoch1,\n",
    "    epoch2,\n",
    "    block=False,\n",
    "):\n",
    "    \"\"\"Plot CKA heatmap.\n",
    "\n",
    "    Args:\n",
    "        path_to_save_figure (str): Path to save figure of CKA heatmap.\n",
    "        cka_matrix (np.ndarray[dim, dim]): CKA heatmap of activation of two models.\n",
    "        reward_state_action (str): \"reward\" (return-to-go), \"state\", or \"action\".\n",
    "        model1 (str): 'gpt2', 'igpt', or 'dt'.\n",
    "        model2 (str): 'gpt2', 'igpt', or 'dt'.\n",
    "        env_name (str): 'hopper', 'halfcheetah', or 'walker2d'.\n",
    "        dataset_name (str): 'medium'.\n",
    "        seed (int): 666.\n",
    "        epoch1 (int): 0 or 40.\n",
    "        epoch2 (int): 0 or 40.\n",
    "        block (bool, optional): If the activation is that of Transformer block, set this True. Defaults to False.\n",
    "    \"\"\"\n",
    "\n",
    "    sns.set_style(\"ticks\")\n",
    "    sns.set_context(\"paper\", 1.5, {\"lines.linewidth\": 2})\n",
    "\n",
    "    ax = sns.heatmap(cka_matrix, vmin=0, vmax=1, square=True)\n",
    "    ax.invert_yaxis()\n",
    "    if model1 == \"dt\":\n",
    "        label1 = \"random init\"\n",
    "    else:\n",
    "        label1 = model1\n",
    "    if model2 == \"dt\":\n",
    "        label2 = \"random init\"\n",
    "    else:\n",
    "        label2 = model2\n",
    "    if block:\n",
    "        plt.xlabel(f\"{label2.upper()} Block\")\n",
    "        plt.ylabel(f\"{label1.upper()} Block\")\n",
    "    else:\n",
    "        plt.xlabel(f\"{label2.upper()} Layers\")\n",
    "        plt.ylabel(f\"{label1.upper()} Layers\")\n",
    "    plt.tight_layout()\n",
    "    if block:\n",
    "        plt.savefig(\n",
    "            f\"{path_to_save_figure}/cka_block_{epoch1}_{epoch2}_{model1}{model2}_{env_name}_{dataset_name}_{seed}_{reward_state_action}.pdf\"\n",
    "        )\n",
    "    else:\n",
    "        plt.savefig(\n",
    "            f\"{path_to_save_figure}/cka_{epoch1}_{epoch2}_{model1}{model2}_{env_name}_{dataset_name}_{seed}_{reward_state_action}.pdf\"\n",
    "        )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7138ce-18a4-474d-ac99-0649f581f26a",
   "metadata": {},
   "source": [
    "## Function for running CKA computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f4b6be7-0640-4c73-a1b6-b997b0ea7f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cka(\n",
    "    path_to_dataset,\n",
    "    path_to_model_checkpoint,\n",
    "    path_to_save_cka,\n",
    "    path_to_save_figure,\n",
    "    seed=666,\n",
    "    model1='gpt2',\n",
    "    model2='gpt2',\n",
    "    epoch1=40,\n",
    "    epoch2=40,\n",
    "    env_name_list=['hopper', 'halfcheetah', 'walker2d'],\n",
    "    block=False,\n",
    "    no_context=False,\n",
    "    device=\"cpu\"\n",
    "    ):\n",
    "    \"\"\"Compute CKA and save it as array and fig.\n",
    "\n",
    "    Args:\n",
    "        path_to_model_checkpoint (str): Path to load model checkpoint.\n",
    "        path_to_save_cka (str): Path to save CKA matrix as np.array.\n",
    "        path_to_save_figure (str): Path to save figure of CKA heatmap.\n",
    "        seed (int, optional): Random seed. Defaults to 666.\n",
    "        model1 (str, optional): 'gpt2', 'igpt', or 'dt'. Defaults to 'gpt2'.\n",
    "        model2 (str, optional): 'gpt2', 'igpt', or 'dt'. Defaults to 'gpt2'.\n",
    "        epoch1 (int, optional): 0 or 40. Defaults to 40.\n",
    "        epoch2 (int, optional): 0 or 40. Defaults to 40.\n",
    "        env_name_list (list, optional): environment name list. Defaults to ['hopper', 'halfcheetah', 'walker2d'].\n",
    "        block (bool, optional): If True, compute CKA for transformer block. Defaults to False.\n",
    "        no_context (bool, optional): If True, compute CKA of K=1. Defaults to False.\n",
    "        device (str): cuda or cpu\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(path_to_save_cka, exist_ok=True)\n",
    "    os.makedirs(path_to_save_figure, exist_ok=True)\n",
    "\n",
    "    dataset_name = 'medium'\n",
    "    device = torch.device(device)\n",
    "    reward_state_action_list = ['action', 'state', 'reward']\n",
    "\n",
    "    for env_name in env_name_list:\n",
    "        \n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "        variant = generate_variant(epoch1, path_to_model_checkpoint, model1, env_name, seed, dataset_name)\n",
    "\n",
    "        if no_context:\n",
    "            variant['load_checkpoint'] = False if epoch1==0 else f'{path_to_model_checkpoint}/{model1}_medium_{env_name}_{seed}_K1/model_{epoch1}.pt'\n",
    "\n",
    "        state_dim, act_dim, max_ep_len, scale = get_data_info(variant)\n",
    "        states, actions, rewards, dones, rtg, timesteps, attention_mask = get_batch(variant, state_dim, act_dim, max_ep_len, scale, device, path_to_dataset)\n",
    "\n",
    "        activation_list = []\n",
    "\n",
    "        # Get activations of model1 and model2, respectvely.\n",
    "        for _ in range(2):\n",
    "    \n",
    "            # For the first iteration, ues the `variant` defined above (model1).\n",
    "            # For the second iteration, ues the `variant` defined below (model2).\n",
    "            activation = get_activation(variant, state_dim, act_dim, max_ep_len, states, actions, rewards, rtg, timesteps, attention_mask, device)\n",
    "            activation_list.append(activation)\n",
    "\n",
    "            variant = generate_variant(epoch2, path_to_model_checkpoint, model2, env_name, seed, dataset_name)\n",
    "\n",
    "            if no_context:\n",
    "                variant['load_checkpoint'] = False if epoch2==0 else f'{path_to_model_checkpoint}/{model2}_medium_{env_name}_{seed}_K1/model_{epoch2}.pt'\n",
    "        \n",
    "        if block:\n",
    "            for reward_state_action in reward_state_action_list:\n",
    "                cka_matrix = []\n",
    "                for key_1, act_1 in tqdm(activation_list[0].items()):\n",
    "                    # Compute CKA only for output of blocks (e.g. DecisionTransformer.transformer.h[0].mlp.dropout)\n",
    "                    if ('dropout' in key_1) and ('mlp' in key_1):\n",
    "                        cka_list = []\n",
    "                        for key_2, act_2 in activation_list[1].items():\n",
    "                            if ('dropout' in key_2) and ('mlp' in key_2):\n",
    "                                cka = compute_cka(act_1, act_2, reward_state_action)\n",
    "                                cka_list.append(cka)\n",
    "                        cka_matrix.append(cka_list)\n",
    "                cka_matrix = np.array(cka_matrix)\n",
    "\n",
    "                np.save(f'{path_to_save_cka}/cka_block_{epoch1}_{epoch2}_{model1}{model2}_{env_name}_{dataset_name}_{seed}_{reward_state_action}.npy', cka_matrix)\n",
    "                plot_cka(path_to_save_figure, cka_matrix, reward_state_action, model1, model2, env_name, dataset_name, seed, epoch1, epoch2, block)\n",
    "        else:\n",
    "            for reward_state_action in reward_state_action_list:\n",
    "                cka_matrix = []\n",
    "                for key_1, act_1 in tqdm(activation_list[0].items()):\n",
    "                    cka_list = []\n",
    "                    for key_2, act_2 in activation_list[1].items():\n",
    "                        cka = compute_cka(act_1, act_2, reward_state_action, timestep=-1)\n",
    "                        cka_list.append(cka)\n",
    "                    cka_matrix.append(cka_list)\n",
    "                cka_matrix = np.array(cka_matrix)\n",
    "\n",
    "                np.save(f'{path_to_save_cka}/cka_{epoch1}_{epoch2}_{model1}{model2}_{env_name}_{dataset_name}_{seed}_{reward_state_action}.npy', cka_matrix)\n",
    "                plot_cka(path_to_save_figure, cka_matrix, reward_state_action, model1, model2, env_name, dataset_name, seed, epoch1, epoch2, block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83d8866b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ba2098c6b4a4e8980b5e19b5ead260a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a1c1b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "env_name = 'hopper'\n",
    "dataset='expert-v2'\n",
    "with open(f'/home/alexrgilbert/repos/pre-training-different-modality-offline-rl/can-wikipedia-help-offline-rl/data/{env_name}-{dataset}.pkl','rb') as f:\n",
    "    trajectories = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0cf9cc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Starting new experiment: hopper expert-v2\n",
      "1027 trajectories, 999494 timesteps found\n",
      "Average return: 3511.36, std: 328.59\n",
      "Max return: 3759.08, min: 1645.28\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "states, traj_lens, returns = [], [], []\n",
    "for path in trajectories:\n",
    "    # if mode == \"delayed\":  # delayed: all rewards moved to end of trajectory\n",
    "    #     path[\"rewards\"][-1] = path[\"rewards\"].sum()\n",
    "    #     path[\"rewards\"][:-1] = 0.0\n",
    "    states.append(path[\"observations\"])\n",
    "    traj_lens.append(len(path[\"observations\"]))\n",
    "    returns.append(path[\"rewards\"].sum())\n",
    "traj_lens, returns = np.array(traj_lens), np.array(returns)\n",
    "\n",
    "# used for input normalization\n",
    "states = np.concatenate(states, axis=0)\n",
    "state_mean, state_std = np.mean(states, axis=0), np.std(states, axis=0) + 1e-6\n",
    "\n",
    "num_timesteps = sum(traj_lens)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(f\"Starting new experiment: {env_name} {dataset}\")\n",
    "print(f\"{len(traj_lens)} trajectories, {num_timesteps} timesteps found\")\n",
    "print(f\"Average return: {np.mean(returns):.2f}, std: {np.std(returns):.2f}\")\n",
    "print(f\"Max return: {np.max(returns):.2f}, min: {np.min(returns):.2f}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "49be24e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'OfflineHopperEnv' object has no attribute 'time_limit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime_limit\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/cs330/lib/python3.9/site-packages/gym/core.py:229\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/core.py?line=223'>224</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, env: Env):\n\u001b[1;32m    <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/core.py?line=224'>225</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Wraps an environment to allow a modular transformation of the :meth:`step` and :meth:`reset` methods.\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/core.py?line=225'>226</a>\u001b[0m \n\u001b[1;32m    <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/core.py?line=226'>227</a>\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/core.py?line=227'>228</a>\u001b[0m \u001b[39m        env: The environment to wrap\u001b[39;00m\n\u001b[0;32m--> <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/core.py?line=228'>229</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/core.py?line=229'>230</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv \u001b[39m=\u001b[39m env\n\u001b[1;32m    <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/core.py?line=231'>232</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_action_space: Optional[spaces\u001b[39m.\u001b[39mSpace] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/cs330/lib/python3.9/site-packages/gym/core.py:229\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/core.py?line=223'>224</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, env: Env):\n\u001b[1;32m    <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/core.py?line=224'>225</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Wraps an environment to allow a modular transformation of the :meth:`step` and :meth:`reset` methods.\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/core.py?line=225'>226</a>\u001b[0m \n\u001b[1;32m    <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/core.py?line=226'>227</a>\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/core.py?line=227'>228</a>\u001b[0m \u001b[39m        env: The environment to wrap\u001b[39;00m\n\u001b[0;32m--> <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/core.py?line=228'>229</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/core.py?line=229'>230</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv \u001b[39m=\u001b[39m env\n\u001b[1;32m    <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/core.py?line=231'>232</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_action_space: Optional[spaces\u001b[39m.\u001b[39mSpace] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/cs330/lib/python3.9/site-packages/d4rl/utils/wrappers.py:43\u001b[0m, in \u001b[0;36mProxyEnv.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m     <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/d4rl/utils/wrappers.py?line=40'>41</a>\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_wrapped_env\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/d4rl/utils/wrappers.py?line=41'>42</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m()\n\u001b[0;32m---> <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/d4rl/utils/wrappers.py?line=42'>43</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wrapped_env, attr)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'OfflineHopperEnv' object has no attribute 'time_limit'"
     ]
    }
   ],
   "source": [
    "e.time_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "34607e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "49e336e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import d4rl\n",
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c71c396c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(-1.0, 1.0, (2,), float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1939888",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at transfo-xl-wt103 were not used when initializing TransfoXLModel: ['crit.out_projs.0', 'crit.out_layers.0.weight', 'crit.out_layers.2.weight', 'crit.out_projs.2', 'crit.out_layers.3.bias', 'crit.out_layers.0.bias', 'crit.out_projs.1', 'crit.cluster_weight', 'crit.out_layers.3.weight', 'crit.out_projs.3', 'crit.out_layers.2.bias', 'crit.out_layers.1.weight', 'crit.cluster_bias', 'crit.out_layers.1.bias']\n",
      "- This IS expected if you are initializing TransfoXLModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TransfoXLModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mn,m \u001b[38;5;129;01min\u001b[39;00m pretrained\u001b[38;5;241m.\u001b[39mnamed_modules():\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pn,p \u001b[38;5;129;01min\u001b[39;00m m\u001b[38;5;241m.\u001b[39mnamed_parameters(recurse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m---> 16\u001b[0m         \u001b[43mparameters\u001b[49m[mn]\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(pformat(parameters))\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_activation\u001b[39m(\n\u001b[1;32m     23\u001b[0m     variant,\n\u001b[1;32m     24\u001b[0m     state_dim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m     device,\n\u001b[1;32m     34\u001b[0m ):\n",
      "Cell \u001b[0;32mIn[4], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mn,m \u001b[38;5;129;01min\u001b[39;00m pretrained\u001b[38;5;241m.\u001b[39mnamed_modules():\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pn,p \u001b[38;5;129;01min\u001b[39;00m m\u001b[38;5;241m.\u001b[39mnamed_parameters(recurse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m---> 16\u001b[0m         \u001b[43mparameters\u001b[49m[mn]\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(pformat(parameters))\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_activation\u001b[39m(\n\u001b[1;32m     23\u001b[0m     variant,\n\u001b[1;32m     24\u001b[0m     state_dim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m     device,\n\u001b[1;32m     34\u001b[0m ):\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/cs330/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py?line=2066'>2067</a>\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py?line=2068'>2069</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py?line=2069'>2070</a>\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[1;32m   <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py?line=2071'>2072</a>\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py?line=2073'>2074</a>\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py?line=2074'>2075</a>\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/cs330/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py?line=2102'>2103</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_input_hook()\n\u001b[1;32m   <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py?line=2104'>2105</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py?line=2105'>2106</a>\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[1;32m   <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py?line=2107'>2108</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n\u001b[1;32m   <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py?line=2109'>2110</a>\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "from transformers import TransfoXLConfig, TransfoXLModel\n",
    "from tqdm._tqdm_notebook import tqdm\n",
    "from pprint import pformat\n",
    "from collections import defaultdict\n",
    "\n",
    "config = TransfoXLConfig()\n",
    "random = TransfoXLModel(config)\n",
    "pretrained = TransfoXLModel.from_pretrained(\"transfo-xl-wt103\")\n",
    "\n",
    "\n",
    "def get_activation(model):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    activation = {}\n",
    "\n",
    "    def extract_activation(name):\n",
    "        def hook(model, input, output):\n",
    "            activation[name] = output.detach()\n",
    "\n",
    "        return hook\n",
    "\n",
    "    def apply_hook(module,layer_id,name):\n",
    "        module.register_forward_hook(extract_activation(f\"{layer_id}.{name}\"))\n",
    "\n",
    "    for i,layer in enumerate(model.layers):\n",
    "        apply_hook(layer.dec_attn.layer_norm,i,'dec_attn.layer_norm')\n",
    "        apply_hook(layer.dec_attn.o_net,i,'dec_attn.o_net')\n",
    "        apply_hook(layer.dec_attn.qkv_net,i,'dec_attn.qkv_net')\n",
    "        apply_hook(layer.dec_attn.r_net,i,'dec_attn.r_net')\n",
    "        apply_hook(layer.pos_ff.CoreNet[0],i,'pos_ff.CoreNet.LinearExpand')\n",
    "        apply_hook(layer.pos_ff.CoreNet[1],i,'pos_ff.CoreNet.ReLU')\n",
    "        apply_hook(layer.pos_ff.CoreNet[2],i,'pos_ff.CoreNet.DropoutExpand')\n",
    "        apply_hook(layer.pos_ff.CoreNet[3],i,'pos_ff.CoreNet.LinearBottleneck')\n",
    "        apply_hook(layer.pos_ff.CoreNet[4],i,'pos_ff.CoreNet.DropoutBottleneck')\n",
    "\n",
    "        _, _, _, _ = model.forward(\n",
    "        states,\n",
    "        actions,\n",
    "        rewards,\n",
    "        rtg[:, :-1],\n",
    "        timesteps,\n",
    "        attention_mask=attention_mask,\n",
    "    )\n",
    "\n",
    "\n",
    "    for mn,m in model.named_modules():\n",
    "        for pn,p in m.named_parameters(recurse=False):\n",
    "            \n",
    "            parameters[mn].append(f'{pn} ({p.shape})')\n",
    "            assert pretrained\n",
    "    print(pformat(parameters))\n",
    "\n",
    "    for block_id in range(len(model.transformer.h)):\n",
    "        model.transformer.h[block_id].ln_1.register_forward_hook(\n",
    "            extract_activation(f\"{block_id}.ln_1\")\n",
    "        )\n",
    "    model.transformer.h[block_id].attn.c_attn.register_forward_hook(\n",
    "        extract_activation(f\"{block_id}.attn.c_attn\")\n",
    "    )\n",
    "    model.transformer.h[block_id].attn.c_proj.register_forward_hook(\n",
    "        extract_activation(f\"{block_id}.attn.c_proj\")\n",
    "    )\n",
    "    model.transformer.h[block_id].attn.attn_dropout.register_forward_hook(\n",
    "        extract_activation(f\"{block_id}.attn.attn_dropout\")\n",
    "    )\n",
    "    model.transformer.h[block_id].attn.resid_dropout.register_forward_hook(\n",
    "        extract_activation(f\"{block_id}.attn.resid_dropout\")\n",
    "    )\n",
    "    model.transformer.h[block_id].ln_2.register_forward_hook(\n",
    "        extract_activation(f\"{block_id}.ln_2\")\n",
    "    )\n",
    "    model.transformer.h[block_id].mlp.c_fc.register_forward_hook(\n",
    "        extract_activation(f\"{block_id}.mlp.c_fc\")\n",
    "    )\n",
    "    model.transformer.h[block_id].mlp.c_proj.register_forward_hook(\n",
    "        extract_activation(f\"{block_id}.mlp.c_proj\")\n",
    "    )\n",
    "    try:\n",
    "        model.transformer.h[block_id].mlp.act.register_forward_hook(\n",
    "            extract_activation(f\"{block_id}.mlp.act\")\n",
    "        )\n",
    "    except:\n",
    "        pass\n",
    "    model.transformer.h[block_id].mlp.dropout.register_forward_hook(\n",
    "        extract_activation(f\"{block_id}.mlp.dropout\")\n",
    "    )\n",
    "\n",
    "    _, _, _, _ = model.forward(\n",
    "        states,\n",
    "        actions,\n",
    "        rewards,\n",
    "        rtg[:, :-1],\n",
    "        timesteps,\n",
    "        attention_mask=attention_mask,\n",
    "    )\n",
    "\n",
    "    activation_sorted = {}\n",
    "    block_name_list = [\n",
    "        \"ln_1\",\n",
    "        \"attn.c_attn\",\n",
    "        \"attn.c_proj\",\n",
    "        \"attn.resid_dropout\",\n",
    "        \"ln_2\",\n",
    "        \"mlp.c_fc\",\n",
    "        \"mlp.c_proj\",\n",
    "        \"mlp.act\",\n",
    "        \"mlp.dropout\",\n",
    "    ]\n",
    "    for block_id in range(len(model.transformer.h)):\n",
    "        for block_name in block_name_list:\n",
    "            try:\n",
    "                activation_sorted[f\"{block_id}.{block_name}\"] = activation[\n",
    "                    f\"{block_id}.{block_name}\"\n",
    "                ]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "# parameters = defaultdict(list)\n",
    "# for mn,m in pretrained.named_modules():\n",
    "#     for pn,p in m.named_parameters(recurse=False):\n",
    "#         parameters[mn].append(f'{pn} ({p.shape})')\n",
    "#         assert pretrained\n",
    "# print(pformat(parameters))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_activation(\n",
    "    variant,\n",
    "    state_dim,\n",
    "    act_dim,\n",
    "    max_ep_len,\n",
    "    states,\n",
    "    actions,\n",
    "    rewards,\n",
    "    rtg,\n",
    "    timesteps,\n",
    "    attention_mask,\n",
    "    device,\n",
    "):\n",
    "    \"\"\"Get activation of a model.\n",
    "\n",
    "    Args:\n",
    "        variant (dict): arguments.\n",
    "        state_dim (int): dimension of state.\n",
    "        act_dim (int): dimension of action.\n",
    "        max_ep_len (int): context length K.\n",
    "        states (torch.Tensor): a batch of states.\n",
    "        actions (torch.Tensor): a batch of actions.\n",
    "        rewards (torch.Tensor): a batch of rewards.\n",
    "        rtg (torch.Tensor): a batch of return-to-go.\n",
    "        timesteps (torch.Tensor): a batch of timesteps.\n",
    "        attention_mask (torch.Tensor): Mask for causal Transformer.\n",
    "        device (torch.device): torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\").\n",
    "\n",
    "    Returns:\n",
    "        dict: {layer_name: activation, ...}\n",
    "    \"\"\"\n",
    "    torch.manual_seed(0)\n",
    "    model = DecisionTransformer(\n",
    "        args=variant,\n",
    "        state_dim=state_dim,\n",
    "        act_dim=act_dim,\n",
    "        max_length=variant[\"K\"],\n",
    "        max_ep_len=max_ep_len,\n",
    "        hidden_size=variant[\"embed_dim\"],\n",
    "        n_layer=variant[\"n_layer\"],\n",
    "        n_head=variant[\"n_head\"],\n",
    "        n_inner=4 * variant[\"embed_dim\"],\n",
    "        activation_function=variant[\"activation_function\"],\n",
    "        n_positions=1024,\n",
    "        resid_pdrop=variant[\"dropout\"],\n",
    "        attn_pdrop=0.1,\n",
    "    ).to(device)\n",
    "    if variant[\"load_checkpoint\"]:\n",
    "        state_dict = torch.load(variant[\"load_checkpoint\"])\n",
    "        model.load_state_dict(state_dict)\n",
    "        print(f\"Loaded from {variant['load_checkpoint']}\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    activation = {}\n",
    "\n",
    "    def extract_activation(name):\n",
    "        def hook(model, input, output):\n",
    "            activation[name] = output.detach()\n",
    "\n",
    "        return hook\n",
    "\n",
    "    for block_id in range(len(model.transformer.h)):\n",
    "        model.transformer.h[block_id].ln_1.register_forward_hook(\n",
    "            extract_activation(f\"{block_id}.ln_1\")\n",
    "        )\n",
    "        model.transformer.h[block_id].attn.c_attn.register_forward_hook(\n",
    "            extract_activation(f\"{block_id}.attn.c_attn\")\n",
    "        )\n",
    "        model.transformer.h[block_id].attn.c_proj.register_forward_hook(\n",
    "            extract_activation(f\"{block_id}.attn.c_proj\")\n",
    "        )\n",
    "        model.transformer.h[block_id].attn.attn_dropout.register_forward_hook(\n",
    "            extract_activation(f\"{block_id}.attn.attn_dropout\")\n",
    "        )\n",
    "        model.transformer.h[block_id].attn.resid_dropout.register_forward_hook(\n",
    "            extract_activation(f\"{block_id}.attn.resid_dropout\")\n",
    "        )\n",
    "        model.transformer.h[block_id].ln_2.register_forward_hook(\n",
    "            extract_activation(f\"{block_id}.ln_2\")\n",
    "        )\n",
    "        model.transformer.h[block_id].mlp.c_fc.register_forward_hook(\n",
    "            extract_activation(f\"{block_id}.mlp.c_fc\")\n",
    "        )\n",
    "        model.transformer.h[block_id].mlp.c_proj.register_forward_hook(\n",
    "            extract_activation(f\"{block_id}.mlp.c_proj\")\n",
    "        )\n",
    "        try:\n",
    "            model.transformer.h[block_id].mlp.act.register_forward_hook(\n",
    "                extract_activation(f\"{block_id}.mlp.act\")\n",
    "            )\n",
    "        except:\n",
    "            pass\n",
    "        model.transformer.h[block_id].mlp.dropout.register_forward_hook(\n",
    "            extract_activation(f\"{block_id}.mlp.dropout\")\n",
    "        )\n",
    "\n",
    "    _, _, _, _ = model.forward(\n",
    "        states,\n",
    "        actions,\n",
    "        rewards,\n",
    "        rtg[:, :-1],\n",
    "        timesteps,\n",
    "        attention_mask=attention_mask,\n",
    "    )\n",
    "\n",
    "    activation_sorted = {}\n",
    "    block_name_list = [\n",
    "        \"ln_1\",\n",
    "        \"attn.c_attn\",\n",
    "        \"attn.c_proj\",\n",
    "        \"attn.resid_dropout\",\n",
    "        \"ln_2\",\n",
    "        \"mlp.c_fc\",\n",
    "        \"mlp.c_proj\",\n",
    "        \"mlp.act\",\n",
    "        \"mlp.dropout\",\n",
    "    ]\n",
    "    for block_id in range(len(model.transformer.h)):\n",
    "        for block_name in block_name_list:\n",
    "            try:\n",
    "                activation_sorted[f\"{block_id}.{block_name}\"] = activation[\n",
    "                    f\"{block_id}.{block_name}\"\n",
    "                ]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    return activation_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c734552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>,\n",
      "            {'layers.0.dec_attn': ['r_r_bias (torch.Size([16, 64]))',\n",
      "                                   'r_w_bias (torch.Size([16, 64]))'],\n",
      "             'layers.0.dec_attn.layer_norm': ['weight (torch.Size([1024]))',\n",
      "                                              'bias (torch.Size([1024]))'],\n",
      "             'layers.0.dec_attn.o_net': ['weight (torch.Size([1024, 1024]))'],\n",
      "             'layers.0.dec_attn.qkv_net': ['weight (torch.Size([3072, 1024]))'],\n",
      "             'layers.0.dec_attn.r_net': ['weight (torch.Size([1024, 1024]))'],\n",
      "             'layers.0.pos_ff.CoreNet.0': ['weight (torch.Size([4096, 1024]))',\n",
      "                                           'bias (torch.Size([4096]))'],\n",
      "             'layers.0.pos_ff.CoreNet.3': ['weight (torch.Size([1024, 4096]))',\n",
      "                                           'bias (torch.Size([1024]))'],\n",
      "             'layers.0.pos_ff.layer_norm': ['weight (torch.Size([1024]))',\n",
      "                                            'bias (torch.Size([1024]))'],\n",
      "             'layers.1.dec_attn': ['r_r_bias (torch.Size([16, 64]))',\n",
      "                                   'r_w_bias (torch.Size([16, 64]))'],\n",
      "             'layers.1.dec_attn.layer_norm': ['weight (torch.Size([1024]))',\n",
      "                                              'bias (torch.Size([1024]))'],\n",
      "             'layers.1.dec_attn.o_net': ['weight (torch.Size([1024, 1024]))'],\n",
      "             'layers.1.dec_attn.qkv_net': ['weight (torch.Size([3072, 1024]))'],\n",
      "             'layers.1.dec_attn.r_net': ['weight (torch.Size([1024, 1024]))'],\n",
      "             'layers.1.pos_ff.CoreNet.0': ['weight (torch.Size([4096, 1024]))',\n",
      "                                           'bias (torch.Size([4096]))'],\n",
      "             'layers.1.pos_ff.CoreNet.3': ['weight (torch.Size([1024, 4096]))',\n",
      "                                           'bias (torch.Size([1024]))'],\n",
      "             'layers.1.pos_ff.layer_norm': ['weight (torch.Size([1024]))',\n",
      "                                            'bias (torch.Size([1024]))'],\n",
      "             'layers.10.dec_attn': ['r_r_bias (torch.Size([16, 64]))',\n",
      "                                    'r_w_bias (torch.Size([16, 64]))'],\n",
      "             'layers.10.dec_attn.layer_norm': ['weight (torch.Size([1024]))',\n",
      "                                               'bias (torch.Size([1024]))'],\n",
      "             'layers.10.dec_attn.o_net': ['weight (torch.Size([1024, 1024]))'],\n",
      "             'layers.10.dec_attn.qkv_net': ['weight (torch.Size([3072, '\n",
      "                                            '1024]))'],\n",
      "             'layers.10.dec_attn.r_net': ['weight (torch.Size([1024, 1024]))'],\n",
      "             'layers.10.pos_ff.CoreNet.0': ['weight (torch.Size([4096, 1024]))',\n",
      "                                            'bias (torch.Size([4096]))'],\n",
      "             'layers.10.pos_ff.CoreNet.3': ['weight (torch.Size([1024, 4096]))',\n",
      "                                            'bias (torch.Size([1024]))'],\n",
      "             'layers.10.pos_ff.layer_norm': ['weight (torch.Size([1024]))',\n",
      "                                             'bias (torch.Size([1024]))'],\n",
      "             'layers.11.dec_attn': ['r_r_bias (torch.Size([16, 64]))',\n",
      "                                    'r_w_bias (torch.Size([16, 64]))'],\n",
      "             'layers.11.dec_attn.layer_norm': ['weight (torch.Size([1024]))',\n",
      "                                               'bias (torch.Size([1024]))'],\n",
      "             'layers.11.dec_attn.o_net': ['weight (torch.Size([1024, 1024]))'],\n",
      "             'layers.11.dec_attn.qkv_net': ['weight (torch.Size([3072, '\n",
      "                                            '1024]))'],\n",
      "             'layers.11.dec_attn.r_net': ['weight (torch.Size([1024, 1024]))'],\n",
      "             'layers.11.pos_ff.CoreNet.0': ['weight (torch.Size([4096, 1024]))',\n",
      "                                            'bias (torch.Size([4096]))'],\n",
      "             'layers.11.pos_ff.CoreNet.3': ['weight (torch.Size([1024, 4096]))',\n",
      "                                            'bias (torch.Size([1024]))'],\n",
      "             'layers.11.pos_ff.layer_norm': ['weight (torch.Size([1024]))',\n",
      "                                             'bias (torch.Size([1024]))'],\n",
      "             'layers.12.dec_attn': ['r_r_bias (torch.Size([16, 64]))',\n",
      "                                    'r_w_bias (torch.Size([16, 64]))'],\n",
      "             'layers.12.dec_attn.layer_norm': ['weight (torch.Size([1024]))',\n",
      "                                               'bias (torch.Size([1024]))'],\n",
      "             'layers.12.dec_attn.o_net': ['weight (torch.Size([1024, 1024]))'],\n",
      "             'layers.12.dec_attn.qkv_net': ['weight (torch.Size([3072, '\n",
      "                                            '1024]))'],\n",
      "             'layers.12.dec_attn.r_net': ['weight (torch.Size([1024, 1024]))'],\n",
      "             'layers.12.pos_ff.CoreNet.0': ['weight (torch.Size([4096, 1024]))',\n",
      "                                            'bias (torch.Size([4096]))'],\n",
      "             'layers.12.pos_ff.CoreNet.3': ['weight (torch.Size([1024, 4096]))',\n",
      "                                            'bias (torch.Size([1024]))'],\n",
      "             'layers.12.pos_ff.layer_norm': ['weight (torch.Size([1024]))',\n",
      "                                             'bias (torch.Size([1024]))'],\n",
      "             'layers.13.dec_attn': ['r_r_bias (torch.Size([16, 64]))',\n",
      "                                    'r_w_bias (torch.Size([16, 64]))'],\n",
      "             'layers.13.dec_attn.layer_norm': ['weight (torch.Size([1024]))',\n",
      "                                               'bias (torch.Size([1024]))'],\n",
      "             'layers.13.dec_attn.o_net': ['weight (torch.Size([1024, 1024]))'],\n",
      "             'layers.13.dec_attn.qkv_net': ['weight (torch.Size([3072, '\n",
      "                                            '1024]))'],\n",
      "             'layers.13.dec_attn.r_net': ['weight (torch.Size([1024, 1024]))'],\n",
      "             'layers.13.pos_ff.CoreNet.0': ['weight (torch.Size([4096, 1024]))',\n",
      "                                            'bias (torch.Size([4096]))'],\n",
      "             'layers.13.pos_ff.CoreNet.3': ['weight (torch.Size([1024, 4096]))',\n",
      "                                            'bias (torch.Size([1024]))'],\n",
      "             'layers.13.pos_ff.layer_norm': ['weight (torch.Size([1024]))',\n",
      "                                             'bias (torch.Size([1024]))'],\n",
      "             'layers.14.dec_attn': ['r_r_bias (torch.Size([16, 64]))',\n",
      "                                    'r_w_bias (torch.Size([16, 64]))'],\n",
      "             'layers.14.dec_attn.layer_norm': ['weight (torch.Size([1024]))',\n",
      "                                               'bias (torch.Size([1024]))'],\n",
      "             'layers.14.dec_attn.o_net': ['weight (torch.Size([1024, 1024]))'],\n",
      "             'layers.14.dec_attn.qkv_net': ['weight (torch.Size([3072, '\n",
      "                                            '1024]))'],\n",
      "             'layers.14.dec_attn.r_net': ['weight (torch.Size([1024, 1024]))'],\n",
      "             'layers.14.pos_ff.CoreNet.0': ['weight (torch.Size([4096, 1024]))',\n",
      "                                            'bias (torch.Size([4096]))'],\n",
      "             'layers.14.pos_ff.CoreNet.3': ['weight (torch.Size([1024, 4096]))',\n",
      "                                            'bias (torch.Size([1024]))'],\n",
      "             'layers.14.pos_ff.layer_norm': ['weight (torch.Size([1024]))',\n",
      "                                             'bias (torch.Size([1024]))'],\n",
      "             'layers.15.dec_attn': ['r_r_bias (torch.Size([16, 64]))',\n",
      "                                    'r_w_bias (torch.Size([16, 64]))'],\n",
      "             'layers.15.dec_attn.layer_norm': ['weight (torch.Size([1024]))',\n",
      "                                               'bias (torch.Size([1024]))'],\n",
      "             'layers.15.dec_attn.o_net': ['weight (torch.Size([1024, 1024]))'],\n",
      "             'layers.15.dec_attn.qkv_net': ['weight (torch.Size([3072, '\n",
      "                                            '1024]))'],\n",
      "             'layers.15.dec_attn.r_net': ['weight (torch.Size([1024, 1024]))'],\n",
      "             'layers.15.pos_ff.CoreNet.0': ['weight (torch.Size([4096, 1024]))',\n",
      "                                            'bias (torch.Size([4096]))'],\n",
      "             'layers.15.pos_ff.CoreNet.3': ['weight (torch.Size([1024, 4096]))',\n",
      "                                            'bias (torch.Size([1024]))'],\n",
      "             'layers.15.pos_ff.layer_norm': ['weight (torch.Size([1024]))',\n",
      "                                             'bias (torch.Size([1024]))'],\n",
      "             'layers.16.dec_attn': ['r_r_bias (torch.Size([16, 64]))',\n",
      "                                    'r_w_bias (torch.Size([16, 64]))'],\n",
      "             'layers.16.dec_attn.layer_norm': ['weight (torch.Size([1024]))',\n",
      "                                               'bias (torch.Size([1024]))'],\n",
      "             'layers.16.dec_attn.o_net': ['weight (torch.Size([1024, 1024]))'],\n",
      "             'layers.16.dec_attn.qkv_net': ['weight (torch.Size([3072, '\n",
      "                                            '1024]))'],\n",
      "             'layers.16.dec_attn.r_net': ['weight (torch.Size([1024, 1024]))'],\n",
      "             'layers.16.pos_ff.CoreNet.0': ['weight (torch.Size([4096, 1024]))',\n",
      "                                            'bias (torch.Size([4096]))'],\n",
      "             'layers.16.pos_ff.CoreNet.3': ['weight (torch.Size([1024, 4096]))',\n",
      "                                            'bias (torch.Size([1024]))'],\n",
      "             'layers.16.pos_ff.layer_norm': ['weight (torch.Size([1024]))',\n",
      "                                             'bias (torch.Size([1024]))'],\n",
      "             'layers.17.dec_attn': ['r_r_bias (torch.Size([16, 64]))',\n",
      "                                    'r_w_bias (torch.Size([16, 64]))'],\n",
      "             'layers.17.dec_attn.layer_norm': ['weight (torch.Size([1024]))',\n",
      "                                               'bias (torch.Size([1024]))'],\n",
      "             'layers.17.dec_attn.o_net': ['weight (torch.Size([1024, 1024]))'],\n",
      "             'layers.17.dec_attn.qkv_net': ['weight (torch.Size([3072, '\n",
      "                                            '1024]))'],\n",
      "             'layers.17.dec_attn.r_net': ['weight (torch.Size([1024, 1024]))'],\n",
      "             'layers.17.pos_ff.CoreNet.0': ['weight (torch.Size([4096, 1024]))',\n",
      "                                            'bias (torch.Size([4096]))'],\n",
      "             'layers.17.pos_ff.CoreNet.3': ['weight (torch.Size([1024, 4096]))',\n",
      "                                            'bias (torch.Size([1024]))'],\n",
      "             'layers.17.pos_ff.layer_norm': ['weight (torch.Size([1024]))',\n",
      "                                             'bias (torch.Size([1024]))'],\n",
      "             'layers.2.dec_attn': ['r_r_bias (torch.Size([16, 64]))',\n",
      "                                   'r_w_bias (torch.Size([16, 64]))'],\n",
      "             'layers.2.dec_attn.layer_norm': ['weight (torch.Size([1024]))',\n",
      "                                              'bias (torch.Size([1024]))'],\n",
      "             'layers.2.dec_attn.o_net': ['weight (torch.Size([1024, 1024]))'],\n",
      "             'layers.2.dec_attn.qkv_net': ['weight (torch.Size([3072, 1024]))'],\n",
      "             'layers.2.dec_attn.r_net': ['weight (torch.Size([1024, 1024]))'],\n",
      "             'layers.2.pos_ff.CoreNet.0': ['weight (torch.Size([4096, 1024]))',\n",
      "                                           'bias (torch.Size([4096]))'],\n",
      "             'layers.2.pos_ff.CoreNet.3': ['weight (torch.Size([1024, 4096]))',\n",
      "                                           'bias (torch.Size([1024]))'],\n",
      "             'layers.2.pos_ff.layer_norm': ['weight (torch.Size([1024]))',\n",
      "                                            'bias (torch.Size([1024]))'],\n",
      "             'layers.3.dec_attn': ['r_r_bias (torch.Size([16, 64]))',\n",
      "                                   'r_w_bias (torch.Size([16, 64]))'],\n",
      "             'layers.3.dec_attn.layer_norm': ['weight (torch.Size([1024]))',\n",
      "                                              'bias (torch.Size([1024]))'],\n",
      "             'layers.3.dec_attn.o_net': ['weight (torch.Size([1024, 1024]))'],\n",
      "             'layers.3.dec_attn.qkv_net': ['weight (torch.Size([3072, 1024]))'],\n",
      "             'layers.3.dec_attn.r_net': ['weight (torch.Size([1024, 1024]))'],\n",
      "             'layers.3.pos_ff.CoreNet.0': ['weight (torch.Size([4096, 1024]))',\n",
      "                                           'bias (torch.Size([4096]))'],\n",
      "             'layers.3.pos_ff.CoreNet.3': ['weight (torch.Size([1024, 4096]))',\n",
      "                                           'bias (torch.Size([1024]))'],\n",
      "             'layers.3.pos_ff.layer_norm': ['weight (torch.Size([1024]))',\n",
      "                                            'bias (torch.Size([1024]))'],\n",
      "             'layers.4.dec_attn': ['r_r_bias (torch.Size([16, 64]))',\n",
      "                                   'r_w_bias (torch.Size([16, 64]))'],\n",
      "             'layers.4.dec_attn.layer_norm': ['weight (torch.Size([1024]))',\n",
      "                                              'bias (torch.Size([1024]))'],\n",
      "             'layers.4.dec_attn.o_net': ['weight (torch.Size([1024, 1024]))'],\n",
      "             'layers.4.dec_attn.qkv_net': ['weight (torch.Size([3072, 1024]))'],\n",
      "             'layers.4.dec_attn.r_net': ['weight (torch.Size([1024, 1024]))'],\n",
      "             'layers.4.pos_ff.CoreNet.0': ['weight (torch.Size([4096, 1024]))',\n",
      "                                           'bias (torch.Size([4096]))'],\n",
      "             'layers.4.pos_ff.CoreNet.3': ['weight (torch.Size([1024, 4096]))',\n",
      "                                           'bias (torch.Size([1024]))'],\n",
      "             'layers.4.pos_ff.layer_norm': ['weight (torch.Size([1024]))',\n",
      "                                            'bias (torch.Size([1024]))'],\n",
      "             'layers.5.dec_attn': ['r_r_bias (torch.Size([16, 64]))',\n",
      "                                   'r_w_bias (torch.Size([16, 64]))'],\n",
      "             'layers.5.dec_attn.layer_norm': ['weight (torch.Size([1024]))',\n",
      "                                              'bias (torch.Size([1024]))'],\n",
      "             'layers.5.dec_attn.o_net': ['weight (torch.Size([1024, 1024]))'],\n",
      "             'layers.5.dec_attn.qkv_net': ['weight (torch.Size([3072, 1024]))'],\n",
      "             'layers.5.dec_attn.r_net': ['weight (torch.Size([1024, 1024]))'],\n",
      "             'layers.5.pos_ff.CoreNet.0': ['weight (torch.Size([4096, 1024]))',\n",
      "                                           'bias (torch.Size([4096]))'],\n",
      "             'layers.5.pos_ff.CoreNet.3': ['weight (torch.Size([1024, 4096]))',\n",
      "                                           'bias (torch.Size([1024]))'],\n",
      "             'layers.5.pos_ff.layer_norm': ['weight (torch.Size([1024]))',\n",
      "                                            'bias (torch.Size([1024]))'],\n",
      "             'layers.6.dec_attn': ['r_r_bias (torch.Size([16, 64]))',\n",
      "                                   'r_w_bias (torch.Size([16, 64]))'],\n",
      "             'layers.6.dec_attn.layer_norm': ['weight (torch.Size([1024]))',\n",
      "                                              'bias (torch.Size([1024]))'],\n",
      "             'layers.6.dec_attn.o_net': ['weight (torch.Size([1024, 1024]))'],\n",
      "             'layers.6.dec_attn.qkv_net': ['weight (torch.Size([3072, 1024]))'],\n",
      "             'layers.6.dec_attn.r_net': ['weight (torch.Size([1024, 1024]))'],\n",
      "             'layers.6.pos_ff.CoreNet.0': ['weight (torch.Size([4096, 1024]))',\n",
      "                                           'bias (torch.Size([4096]))'],\n",
      "             'layers.6.pos_ff.CoreNet.3': ['weight (torch.Size([1024, 4096]))',\n",
      "                                           'bias (torch.Size([1024]))'],\n",
      "             'layers.6.pos_ff.layer_norm': ['weight (torch.Size([1024]))',\n",
      "                                            'bias (torch.Size([1024]))'],\n",
      "             'layers.7.dec_attn': ['r_r_bias (torch.Size([16, 64]))',\n",
      "                                   'r_w_bias (torch.Size([16, 64]))'],\n",
      "             'layers.7.dec_attn.layer_norm': ['weight (torch.Size([1024]))',\n",
      "                                              'bias (torch.Size([1024]))'],\n",
      "             'layers.7.dec_attn.o_net': ['weight (torch.Size([1024, 1024]))'],\n",
      "             'layers.7.dec_attn.qkv_net': ['weight (torch.Size([3072, 1024]))'],\n",
      "             'layers.7.dec_attn.r_net': ['weight (torch.Size([1024, 1024]))'],\n",
      "             'layers.7.pos_ff.CoreNet.0': ['weight (torch.Size([4096, 1024]))',\n",
      "                                           'bias (torch.Size([4096]))'],\n",
      "             'layers.7.pos_ff.CoreNet.3': ['weight (torch.Size([1024, 4096]))',\n",
      "                                           'bias (torch.Size([1024]))'],\n",
      "             'layers.7.pos_ff.layer_norm': ['weight (torch.Size([1024]))',\n",
      "                                            'bias (torch.Size([1024]))'],\n",
      "             'layers.8.dec_attn': ['r_r_bias (torch.Size([16, 64]))',\n",
      "                                   'r_w_bias (torch.Size([16, 64]))'],\n",
      "             'layers.8.dec_attn.layer_norm': ['weight (torch.Size([1024]))',\n",
      "                                              'bias (torch.Size([1024]))'],\n",
      "             'layers.8.dec_attn.o_net': ['weight (torch.Size([1024, 1024]))'],\n",
      "             'layers.8.dec_attn.qkv_net': ['weight (torch.Size([3072, 1024]))'],\n",
      "             'layers.8.dec_attn.r_net': ['weight (torch.Size([1024, 1024]))'],\n",
      "             'layers.8.pos_ff.CoreNet.0': ['weight (torch.Size([4096, 1024]))',\n",
      "                                           'bias (torch.Size([4096]))'],\n",
      "             'layers.8.pos_ff.CoreNet.3': ['weight (torch.Size([1024, 4096]))',\n",
      "                                           'bias (torch.Size([1024]))'],\n",
      "             'layers.8.pos_ff.layer_norm': ['weight (torch.Size([1024]))',\n",
      "                                            'bias (torch.Size([1024]))'],\n",
      "             'layers.9.dec_attn': ['r_r_bias (torch.Size([16, 64]))',\n",
      "                                   'r_w_bias (torch.Size([16, 64]))'],\n",
      "             'layers.9.dec_attn.layer_norm': ['weight (torch.Size([1024]))',\n",
      "                                              'bias (torch.Size([1024]))'],\n",
      "             'layers.9.dec_attn.o_net': ['weight (torch.Size([1024, 1024]))'],\n",
      "             'layers.9.dec_attn.qkv_net': ['weight (torch.Size([3072, 1024]))'],\n",
      "             'layers.9.dec_attn.r_net': ['weight (torch.Size([1024, 1024]))'],\n",
      "             'layers.9.pos_ff.CoreNet.0': ['weight (torch.Size([4096, 1024]))',\n",
      "                                           'bias (torch.Size([4096]))'],\n",
      "             'layers.9.pos_ff.CoreNet.3': ['weight (torch.Size([1024, 4096]))',\n",
      "                                           'bias (torch.Size([1024]))'],\n",
      "             'layers.9.pos_ff.layer_norm': ['weight (torch.Size([1024]))',\n",
      "                                            'bias (torch.Size([1024]))'],\n",
      "             'word_emb.emb_layers.0': ['weight (torch.Size([20000, 1024]))'],\n",
      "             'word_emb.emb_layers.1': ['weight (torch.Size([20000, 256]))'],\n",
      "             'word_emb.emb_layers.2': ['weight (torch.Size([160000, 64]))'],\n",
      "             'word_emb.emb_layers.3': ['weight (torch.Size([67735, 16]))'],\n",
      "             'word_emb.emb_projs': ['0 (torch.Size([1024, 1024]))',\n",
      "                                    '1 (torch.Size([1024, 256]))',\n",
      "                                    '2 (torch.Size([1024, 64]))',\n",
      "                                    '3 (torch.Size([1024, 16]))']})\n"
     ]
    }
   ],
   "source": [
    "from transformers import TransfoXLConfig, TransfoXLModel\n",
    "\n",
    "# # Initializing a Transformer XL configuration\n",
    "configuration = TransfoXLConfig()\n",
    "\n",
    "# # Initializing a model (with random weights) from the configuration\n",
    "model = TransfoXLModel(configuration)\n",
    "\n",
    "# # Accessing the model configuration\n",
    "# configuration = model.config\n",
    "model\n",
    "parameters = defaultdict(list)\n",
    "for mn,m in pretrained.named_modules():\n",
    "    for pn,p in m.named_parameters(recurse=False):\n",
    "        parameters[mn].append(f'{pn} ({p.shape})')\n",
    "        assert pretrained\n",
    "print(pformat(parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2cca12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RelPartialLearnableDecoderLayer(\n",
       "  (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
       "    (qkv_net): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (dropatt): Dropout(p=0.0, inplace=False)\n",
       "    (o_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (r_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "  )\n",
       "  (pos_ff): PositionwiseFF(\n",
       "    (CoreNet): Sequential(\n",
       "      (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      (4): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60cf388e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dec_attn\n",
      "dec_attn.qkv_net\n",
      "dec_attn.drop\n",
      "dec_attn.dropatt\n",
      "dec_attn.o_net\n",
      "dec_attn.layer_norm\n",
      "dec_attn.r_net\n",
      "pos_ff\n",
      "pos_ff.CoreNet\n",
      "pos_ff.CoreNet.0\n",
      "pos_ff.CoreNet.1\n",
      "pos_ff.CoreNet.2\n",
      "pos_ff.CoreNet.3\n",
      "pos_ff.CoreNet.4\n",
      "pos_ff.layer_norm\n"
     ]
    }
   ],
   "source": [
    "for mn,m in model.layers[0].named_modules():\n",
    "    print(mn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735d8efc-7969-4f88-bf51-62ba74fda79a",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e3fa8e0-a1ed-4cb2-bb4b-c8adb9083795",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexrgilbert/.conda/envs/cs330/lib/python3.9/site-packages/gym/envs/registration.py:555: UserWarning: \u001b[33mWARN: The environment Hopper-v3 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
      "  spec.namespace = self._ns\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "\nMissing path to your environment variable. \nCurrent values LD_LIBRARY_PATH=/home/alexrgilbert/.conda/envs/cs330/lib/python3.9/site-packages/cv2/../../lib64:\nPlease add following line to .bashrc:\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/alexrgilbert/.mujoco/mujoco210/bin",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m path_to_save_cka \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath_to_save_cka\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m path_to_save_figure \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath_to_save_figure\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m cka_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mrun_cka\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_to_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_to_model_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_to_save_cka\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_to_save_figure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m666\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgpt2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgpt2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepoch1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepoch2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv_name_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhopper\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhalfcheetah\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwalker2d\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mno_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 49\u001b[0m, in \u001b[0;36mrun_cka\u001b[0;34m(path_to_dataset, path_to_model_checkpoint, path_to_save_cka, path_to_save_figure, seed, model1, model2, epoch1, epoch2, env_name_list, block, no_context, device)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_context:\n\u001b[1;32m     47\u001b[0m     variant[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload_checkpoint\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m epoch1\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_to_model_checkpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_medium_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_K1/model_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 49\u001b[0m state_dim, act_dim, max_ep_len, scale \u001b[38;5;241m=\u001b[39m \u001b[43mget_data_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m states, actions, rewards, dones, rtg, timesteps, attention_mask \u001b[38;5;241m=\u001b[39m get_batch(variant, state_dim, act_dim, max_ep_len, scale, device, path_to_dataset)\n\u001b[1;32m     52\u001b[0m activation_list \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/repos/pre-training-different-modality-offline-rl/can-wikipedia-help-offline-rl/analysis/section-51-activation-similarity/../sample_batch_data.py:53\u001b[0m, in \u001b[0;36mget_data_info\u001b[0;34m(variant)\u001b[0m\n\u001b[1;32m     <a href='file:///~/repos/pre-training-different-modality-offline-rl/can-wikipedia-help-offline-rl/analysis/section-51-activation-similarity/../sample_batch_data.py?line=49'>50</a>\u001b[0m exp_prefix \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mgroup_name\u001b[39m}\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m{\u001b[39;00mrandom\u001b[39m.\u001b[39mrandint(\u001b[39mint\u001b[39m(\u001b[39m1e5\u001b[39m),\u001b[39m \u001b[39m\u001b[39mint\u001b[39m(\u001b[39m1e6\u001b[39m)\u001b[39m \u001b[39m\u001b[39m-\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='file:///~/repos/pre-training-different-modality-offline-rl/can-wikipedia-help-offline-rl/analysis/section-51-activation-similarity/../sample_batch_data.py?line=51'>52</a>\u001b[0m \u001b[39mif\u001b[39;00m env_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhopper\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> <a href='file:///~/repos/pre-training-different-modality-offline-rl/can-wikipedia-help-offline-rl/analysis/section-51-activation-similarity/../sample_batch_data.py?line=52'>53</a>\u001b[0m     env \u001b[39m=\u001b[39m gym\u001b[39m.\u001b[39;49mmake(\u001b[39m\"\u001b[39;49m\u001b[39mHopper-v3\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='file:///~/repos/pre-training-different-modality-offline-rl/can-wikipedia-help-offline-rl/analysis/section-51-activation-similarity/../sample_batch_data.py?line=53'>54</a>\u001b[0m     max_ep_len \u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m\n\u001b[1;32m     <a href='file:///~/repos/pre-training-different-modality-offline-rl/can-wikipedia-help-offline-rl/analysis/section-51-activation-similarity/../sample_batch_data.py?line=54'>55</a>\u001b[0m     env_targets \u001b[39m=\u001b[39m [\u001b[39m3600\u001b[39m, \u001b[39m1800\u001b[39m]  \u001b[39m# evaluation conditioning targets\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/cs330/lib/python3.9/site-packages/gym/envs/registration.py:581\u001b[0m, in \u001b[0;36mmake\u001b[0;34m(id, max_episode_steps, autoreset, apply_api_compatibility, disable_env_checker, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/envs/registration.py?line=578'>579</a>\u001b[0m         \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mRegistrationError(message)\n\u001b[1;32m    <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/envs/registration.py?line=579'>580</a>\u001b[0m     \u001b[39melif\u001b[39;00m latest_versioned_spec \u001b[39mand\u001b[39;00m spec\u001b[39m.\u001b[39mversion \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/envs/registration.py?line=580'>581</a>\u001b[0m         message \u001b[39m=\u001b[39m (\n\u001b[1;32m    <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/envs/registration.py?line=581'>582</a>\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt register the unversioned environment `\u001b[39m\u001b[39m{\u001b[39;00mspec\u001b[39m.\u001b[39mid\u001b[39m}\u001b[39;00m\u001b[39m` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/envs/registration.py?line=582'>583</a>\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwhen version `\u001b[39m\u001b[39m{\u001b[39;00mlatest_versioned_spec\u001b[39m.\u001b[39mversion\u001b[39m}\u001b[39;00m\u001b[39m` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/envs/registration.py?line=583'>584</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mof the same name already exists. Note: the default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/envs/registration.py?line=584'>585</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mbehavior is that the `gym.make` with the unversioned \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/envs/registration.py?line=585'>586</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39menvironment will return the latest versioned environment.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/envs/registration.py?line=586'>587</a>\u001b[0m         )\n\u001b[1;32m    <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/envs/registration.py?line=587'>588</a>\u001b[0m         \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mRegistrationError(message)\n\u001b[1;32m    <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/envs/registration.py?line=588'>589</a>\u001b[0m \u001b[39m# We might not find this namespace or name in which case\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/envs/registration.py?line=589'>590</a>\u001b[0m \u001b[39m# we should continue to register the environment.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/cs330/lib/python3.9/site-packages/gym/envs/registration.py:61\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/envs/registration.py?line=59'>60</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse_env_id\u001b[39m(\u001b[39mid\u001b[39m: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Optional[\u001b[39mstr\u001b[39m], \u001b[39mstr\u001b[39m, Optional[\u001b[39mint\u001b[39m]]:\n\u001b[0;32m---> <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/envs/registration.py?line=60'>61</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Parse environment ID string format.\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/envs/registration.py?line=61'>62</a>\u001b[0m \n\u001b[1;32m     <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/envs/registration.py?line=62'>63</a>\u001b[0m \u001b[39m    This format is true today, but it's *not* an official spec.\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/envs/registration.py?line=63'>64</a>\u001b[0m \u001b[39m    [username/](env-name)-v(version)    env-name is group 1, version is group 2\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/envs/registration.py?line=64'>65</a>\u001b[0m \n\u001b[1;32m     <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/envs/registration.py?line=65'>66</a>\u001b[0m \u001b[39m    2016-10-31: We're experimentally expanding the environment ID format\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/envs/registration.py?line=66'>67</a>\u001b[0m \u001b[39m    to include an optional username.\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/envs/registration.py?line=67'>68</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/envs/registration.py?line=68'>69</a>\u001b[0m     match \u001b[39m=\u001b[39m ENV_ID_RE\u001b[39m.\u001b[39mfullmatch(\u001b[39mid\u001b[39m)\n\u001b[1;32m     <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/envs/registration.py?line=69'>70</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m match:\n",
      "File \u001b[0;32m~/.conda/envs/cs330/lib/python3.9/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.conda/envs/cs330/lib/python3.9/importlib/__init__.py?line=124'>125</a>\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.conda/envs/cs330/lib/python3.9/importlib/__init__.py?line=125'>126</a>\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> <a href='file:///~/.conda/envs/cs330/lib/python3.9/importlib/__init__.py?line=126'>127</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:972\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:850\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/cs330/lib/python3.9/site-packages/gym/envs/mujoco/__init__.py:1\u001b[0m\n\u001b[0;32m----> <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/envs/mujoco/__init__.py?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgym\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39menvs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmujoco\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmujoco_env\u001b[39;00m \u001b[39mimport\u001b[39;00m MujocoEnv\n\u001b[1;32m      <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/envs/mujoco/__init__.py?line=2'>3</a>\u001b[0m \u001b[39m# ^^^^^ so that user gets the correct error\u001b[39;00m\n\u001b[1;32m      <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/envs/mujoco/__init__.py?line=3'>4</a>\u001b[0m \u001b[39m# message if mujoco is not installed correctly\u001b[39;00m\n\u001b[1;32m      <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/envs/mujoco/__init__.py?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgym\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39menvs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmujoco\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mant\u001b[39;00m \u001b[39mimport\u001b[39;00m AntEnv\n",
      "File \u001b[0;32m~/.conda/envs/cs330/lib/python3.9/site-packages/gym/envs/mujoco/mujoco_env.py:12\u001b[0m\n\u001b[1;32m      <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/envs/mujoco/mujoco_env.py?line=8'>9</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgym\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/envs/mujoco/mujoco_env.py?line=10'>11</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/envs/mujoco/mujoco_env.py?line=11'>12</a>\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mmujoco_py\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/envs/mujoco/mujoco_env.py?line=12'>13</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/envs/mujoco/mujoco_env.py?line=13'>14</a>\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mDependencyNotInstalled(\n\u001b[1;32m     <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/envs/mujoco/mujoco_env.py?line=14'>15</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. (HINT: you need to install mujoco_py, and also perform the setup instructions here: https://github.com/openai/mujoco-py/.)\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/envs/mujoco/mujoco_env.py?line=15'>16</a>\u001b[0m             e\n\u001b[1;32m     <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/envs/mujoco/mujoco_env.py?line=16'>17</a>\u001b[0m         )\n\u001b[1;32m     <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/gym/envs/mujoco/mujoco_env.py?line=17'>18</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/cs330/lib/python3.9/site-packages/mujoco_py/__init__.py:2\u001b[0m\n\u001b[1;32m      <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/mujoco_py/__init__.py?line=0'>1</a>\u001b[0m \u001b[39m#!/usr/bin/env python\u001b[39;00m\n\u001b[0;32m----> <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/mujoco_py/__init__.py?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmujoco_py\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbuilder\u001b[39;00m \u001b[39mimport\u001b[39;00m cymj, ignore_mujoco_warnings, functions, MujocoException\n\u001b[1;32m      <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/mujoco_py/__init__.py?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmujoco_py\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgenerated\u001b[39;00m \u001b[39mimport\u001b[39;00m const\n\u001b[1;32m      <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/mujoco_py/__init__.py?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmujoco_py\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmjrenderpool\u001b[39;00m \u001b[39mimport\u001b[39;00m MjRenderPool\n",
      "File \u001b[0;32m~/.conda/envs/cs330/lib/python3.9/site-packages/mujoco_py/builder.py:504\u001b[0m\n\u001b[1;32m    <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/mujoco_py/builder.py?line=499'>500</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m module\u001b[39m.\u001b[39mlib\u001b[39m.\u001b[39m__fun\n\u001b[1;32m    <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/mujoco_py/builder.py?line=502'>503</a>\u001b[0m mujoco_path \u001b[39m=\u001b[39m discover_mujoco()\n\u001b[0;32m--> <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/mujoco_py/builder.py?line=503'>504</a>\u001b[0m cymj \u001b[39m=\u001b[39m load_cython_ext(mujoco_path)\n\u001b[1;32m    <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/mujoco_py/builder.py?line=506'>507</a>\u001b[0m \u001b[39m# Trick to expose all mj* functions from mujoco in mujoco_py.*\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/mujoco_py/builder.py?line=507'>508</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mdict2\u001b[39;00m(\u001b[39mobject\u001b[39m):\n",
      "File \u001b[0;32m~/.conda/envs/cs330/lib/python3.9/site-packages/mujoco_py/builder.py:74\u001b[0m, in \u001b[0;36mload_cython_ext\u001b[0;34m(mujoco_path)\u001b[0m\n\u001b[1;32m     <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/mujoco_py/builder.py?line=71'>72</a>\u001b[0m     Builder \u001b[39m=\u001b[39m MacExtensionBuilder\n\u001b[1;32m     <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/mujoco_py/builder.py?line=72'>73</a>\u001b[0m \u001b[39melif\u001b[39;00m sys\u001b[39m.\u001b[39mplatform \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mlinux\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/mujoco_py/builder.py?line=73'>74</a>\u001b[0m     _ensure_set_env_var(\u001b[39m\"\u001b[39;49m\u001b[39mLD_LIBRARY_PATH\u001b[39;49m\u001b[39m\"\u001b[39;49m, lib_path)\n\u001b[1;32m     <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/mujoco_py/builder.py?line=74'>75</a>\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mgetenv(\u001b[39m'\u001b[39m\u001b[39mMUJOCO_PY_FORCE_CPU\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m get_nvidia_lib_dir() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/mujoco_py/builder.py?line=75'>76</a>\u001b[0m         _ensure_set_env_var(\u001b[39m\"\u001b[39m\u001b[39mLD_LIBRARY_PATH\u001b[39m\u001b[39m\"\u001b[39m, get_nvidia_lib_dir())\n",
      "File \u001b[0;32m~/.conda/envs/cs330/lib/python3.9/site-packages/mujoco_py/builder.py:120\u001b[0m, in \u001b[0;36m_ensure_set_env_var\u001b[0;34m(var_name, lib_path)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/mujoco_py/builder.py?line=117'>118</a>\u001b[0m paths \u001b[39m=\u001b[39m [os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mabspath(path) \u001b[39mfor\u001b[39;00m path \u001b[39min\u001b[39;00m paths]\n\u001b[1;32m    <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/mujoco_py/builder.py?line=118'>119</a>\u001b[0m \u001b[39mif\u001b[39;00m lib_path \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m paths:\n\u001b[0;32m--> <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/mujoco_py/builder.py?line=119'>120</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mMissing path to your environment variable. \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/mujoco_py/builder.py?line=120'>121</a>\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mCurrent values \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/mujoco_py/builder.py?line=121'>122</a>\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mPlease add following line to .bashrc:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/mujoco_py/builder.py?line=122'>123</a>\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mexport \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m=$\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (var_name, os\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39mget(var_name, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m    <a href='file:///~/.conda/envs/cs330/lib/python3.9/site-packages/mujoco_py/builder.py?line=123'>124</a>\u001b[0m                                           var_name, var_name, lib_path))\n",
      "\u001b[0;31mException\u001b[0m: \nMissing path to your environment variable. \nCurrent values LD_LIBRARY_PATH=/home/alexrgilbert/.conda/envs/cs330/lib/python3.9/site-packages/cv2/../../lib64:\nPlease add following line to .bashrc:\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/alexrgilbert/.mujoco/mujoco210/bin"
     ]
    }
   ],
   "source": [
    "path_to_dataset = 'path_to_dataset'\n",
    "path_to_model_checkpoint =  'path_to_model_checkpoint'\n",
    "path_to_save_cka = 'path_to_save_cka'\n",
    "path_to_save_figure = 'path_to_save_figure'\n",
    "cka_matrix = run_cka(\n",
    "    path_to_dataset,\n",
    "    path_to_model_checkpoint,\n",
    "    path_to_save_cka,\n",
    "    path_to_save_figure,\n",
    "    seed=666,\n",
    "    model1='gpt2',\n",
    "    model2='gpt2',\n",
    "    epoch1=40,\n",
    "    epoch2=40,\n",
    "    env_name_list=['hopper', 'halfcheetah', 'walker2d'],\n",
    "    block=False,\n",
    "    no_context=False,\n",
    "    device=\"cpu\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0634aba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('transformer_genralization')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "e69258a44f8e7625f8a17da91770617d51f6311f8535e6184b95ec1daa3f2df5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
